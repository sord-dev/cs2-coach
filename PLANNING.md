# CS2 AI Coach - Project Architecture & Status

## ğŸ¯ Project Overview

CS2 AI Coach is a sophisticated Counter-Strike 2 statistical analysis engine available in two deployment modes:

1. **Live HTTP API**: Production-ready statistical analysis deployed on Cloudflare Workers
2. **Local MCP Server**: For Claude Desktop integration with optional AI enhancement

**Current Status**: âœ… **Production Ready** - Successfully deployed and operational.

## ğŸŒ Deployment Architecture

### Production HTTP API (Primary)
- **URL**: https://cs2-coach.cs2-stats.workers.dev/
- **Platform**: Cloudflare Workers (Edge deployment)
- **Features**: Fast statistical analysis, automatic scaling, zero-downtime updates
- **Response Time**: <5 seconds for comprehensive analysis
- **AI**: Disabled for consistent performance (statistical insights only)

### Local MCP Server (Development/Power Users)
- **Platform**: Local Node.js server
- **Features**: Full statistical engine + optional AI commentary via Ollama
- **Integration**: Claude Desktop via MCP protocol
- **AI**: Optional Ollama integration for enhanced coaching commentary

## ğŸ“Š Core Capabilities

### Statistical Analysis Engine
- **Personal Baselines**: Rolling averages with confidence intervals
- **Tilt Detection**: Research-validated thresholds (>650ms reaction time, >15% preaim degradation)
- **Performance States**: Flow state, mechanical inconsistency, tilt cascade, baseline normal
- **Correlation Analysis**: Pearson/Spearman with statistical significance testing
- **Pattern Recognition**: Momentum analysis, cascade detection, contextual clustering

### API Endpoints (Production)
```
POST /api/coaching-advice     - Get personalized coaching advice
POST /api/enhanced-analysis   - Deep statistical performance analysis  
POST /api/player-performance  - Track improvement over time
POST /api/rank-analysis      - Compare to target ranks
```

### MCP Tools (Local)
```
get_coaching_advice          - Enhanced with personal baselines and state detection
analyze_specific_area        - Deep dive with correlation analysis
track_improvement           - Progress monitoring with statistical significance
compare_to_rank            - Adaptive benchmarks with tier-aware thresholds
```

## ğŸ—ï¸ Technical Architecture

### Clean Project Structure (Post-Cleanup)
```
cs2-coach-mcp-server/
â”œâ”€â”€ README.md                    # Main documentation
â”œâ”€â”€ CLAUDE.md                    # Project instructions
â”œâ”€â”€ PLANNING.md                  # This file - architecture overview
â”œâ”€â”€ TASK.md                      # Development task tracking
â”œâ”€â”€ package.json                 # Dependencies and scripts
â”œâ”€â”€ tsconfig.json               # TypeScript configuration
â”œâ”€â”€ wrangler.toml              # Cloudflare Workers config
â”œâ”€â”€ vercel.json                # Vercel deployment config (alternate)
â”œâ”€â”€ railway.json               # Railway deployment config (alternate)
â”‚
â”œâ”€â”€ modelfiles/                 # Ollama model definitions (local AI)
â”‚   â”œâ”€â”€ cs2-coach-basic.modelfile
â”‚   â””â”€â”€ cs2-coach-enhanced.modelfile
â”‚
â”œâ”€â”€ scripts/                   # Utility scripts
â”‚   â”œâ”€â”€ test-mcp-compliance.js
â”‚   â”œâ”€â”€ test-ollama-health.js
â”‚   â””â”€â”€ verify-deployment-ready.js
â”‚
â”œâ”€â”€ src/                       # Source code
â”‚   â”œâ”€â”€ server.ts             # MCP server entry point
â”‚   â”œâ”€â”€ worker.ts             # Cloudflare Workers entry point
â”‚   â”œâ”€â”€ http-server.ts        # HTTP API server
â”‚   â”œâ”€â”€ http-server-standalone.ts
â”‚   â”‚
â”‚   â”œâ”€â”€ commands/             # MCP tool definitions (embedded)
â”‚   â”‚   â””â”€â”€ index.ts
â”‚   â”‚
â”‚   â”œâ”€â”€ handlers/             # Request handlers (shared by MCP/HTTP)
â”‚   â”‚   â”œâ”€â”€ coachingHandler.ts
â”‚   â”‚   â”œâ”€â”€ enhancedAnalysisHandler.ts
â”‚   â”‚   â”œâ”€â”€ areaAnalysisHandler.ts
â”‚   â”‚   â”œâ”€â”€ improvementHandler.ts
â”‚   â”‚   â””â”€â”€ rankComparisonHandler.ts
â”‚   â”‚
â”‚   â”œâ”€â”€ services/             # Business logic
â”‚   â”‚   â”œâ”€â”€ leetify/          # Leetify API integration
â”‚   â”‚   â”‚   â”œâ”€â”€ index.ts
â”‚   â”‚   â”‚   â””â”€â”€ stats.ts
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ ollama/           # AI service (optional)
â”‚   â”‚   â”‚   â”œâ”€â”€ index.ts      # Ollama implementation
â”‚   â”‚   â”‚   â”œâ”€â”€ noop.ts       # No-op implementation
â”‚   â”‚   â”‚   â”œâ”€â”€ interface.ts  # Service abstraction
â”‚   â”‚   â”‚   â”œâ”€â”€ prompts.ts
â”‚   â”‚   â”‚   â””â”€â”€ error.ts
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ data-transformer/ # Statistical engine
â”‚   â”‚   â”‚   â””â”€â”€ index.ts
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ analysis/         # Statistical analysis components
â”‚   â”‚   â”‚   â”œâ”€â”€ metrics.ts
â”‚   â”‚   â”‚   â”œâ”€â”€ area.ts
â”‚   â”‚   â”‚   â”œâ”€â”€ correlation-analyzer.ts
â”‚   â”‚   â”‚   â”œâ”€â”€ pattern-detector.ts
â”‚   â”‚   â”‚   â”œâ”€â”€ state-classifier.ts
â”‚   â”‚   â”‚   â””â”€â”€ adaptive-thresholds.ts
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ baseline/         # Personal baseline system
â”‚   â”‚   â”‚   â”œâ”€â”€ baseline-calculator.ts
â”‚   â”‚   â”‚   â””â”€â”€ baseline-storage.ts
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ detection/        # Tilt detection
â”‚   â”‚   â”‚   â””â”€â”€ tilt-detector.ts
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ common/          # Shared constants
â”‚   â”‚       â””â”€â”€ constants.ts
â”‚   â”‚
â”‚   â”œâ”€â”€ types/               # TypeScript definitions
â”‚   â”‚   â”œâ”€â”€ index.ts
â”‚   â”‚   â”œâ”€â”€ coaching.ts
â”‚   â”‚   â”œâ”€â”€ leetify.ts
â”‚   â”‚   â”œâ”€â”€ analysis.ts
â”‚   â”‚   â”œâ”€â”€ tilt.ts
â”‚   â”‚   â”œâ”€â”€ config.ts
â”‚   â”‚   â”œâ”€â”€ errors.ts
â”‚   â”‚   â””â”€â”€ utility.ts
â”‚   â”‚
â”‚   â”œâ”€â”€ utils/               # Utility functions
â”‚   â”‚   â””â”€â”€ helpers.ts
â”‚   â”‚
â”‚   â”œâ”€â”€ data/                # Static data (embedded for deployment)
â”‚   â”‚   â””â”€â”€ rank-distribution.ts
â”‚   â”‚
â”‚   â””â”€â”€ cs2-rank-distribution.json  # Rank distribution data
â”‚
â”œâ”€â”€ tests/                   # Test suites
â”‚   â”œâ”€â”€ unit/               # Unit tests
â”‚   â”œâ”€â”€ integration/        # Integration tests
â”‚   â””â”€â”€ quality-assurance/  # QA tests
â”‚
â”œâ”€â”€ jest.config.cjs         # Jest configuration
â”œâ”€â”€ jest.integration.config.cjs
â””â”€â”€ dist/                   # Build output (generated)
```

## ğŸ”„ Data Flow Architecture

### Production HTTP API Flow
```
HTTP Request â†’ Worker â†’ Handler â†’ Service Layer â†’ Leetify API â†’ Statistical Analysis â†’ JSON Response
```

### Local MCP Flow  
```
Claude Desktop â†’ MCP Protocol â†’ Handler â†’ Service Layer â†’ Statistical Analysis + Optional AI â†’ MCP Response
```

### Service Layer Architecture
```
Interface Abstraction (IAICoachService)
â”œâ”€â”€ OllamaCoachService (Local AI commentary)
â””â”€â”€ NoOpAIService (Statistical-only analysis)

Shared Components:
â”œâ”€â”€ LeetifyClient (API integration with rate limiting)
â”œâ”€â”€ DataTransformer (Statistical analysis engine)
â”œâ”€â”€ BaselineCalculator (Personal performance tracking)
â”œâ”€â”€ TiltDetector (Performance state analysis)
â”œâ”€â”€ CorrelationAnalyzer (Pattern identification)
â””â”€â”€ StateClassifier (Performance categorization)
```

## âš¡ Performance Characteristics

### Response Times
- **HTTP API**: <5 seconds (statistical analysis only)
- **MCP + Statistics**: <5 seconds (same statistical engine)
- **MCP + AI**: <15 seconds (with Ollama commentary)

### Resource Usage
- **Cloudflare Workers**: 287KB compressed, starts in ~2ms
- **Local MCP**: <500MB RAM for statistical analysis
- **Local MCP + AI**: <2GB RAM (includes Ollama model)

### Caching Strategy
- **Personal baselines**: 24-hour TTL with incremental updates
- **Statistical computations**: 1-hour cache for complex analysis
- **API responses**: Edge caching on Cloudflare

## ğŸ§  AI Integration Strategy

### Deployment-Aware AI
- **Production (Workers)**: AI disabled (`DISABLE_AI=true`) for consistent performance
- **Local Development**: Optional AI via Ollama for enhanced coaching commentary
- **Service Abstraction**: Clean interface allows AI on/off without code changes

### AI Service Architecture
```typescript
interface IAICoachService {
  analyzeGameplay(request): Promise<CoachingResponse>;
  // ... other methods
}

// Production: NoOpAIService (statistics only)
// Development: OllamaCoachService (statistics + AI commentary)
```

## ğŸ”’ Security & Privacy

### Data Handling
- **No persistent storage**: All processing is stateless
- **Privacy-first**: Statistical analysis without data retention
- **Rate limiting**: Respects Leetify API limits (1 req/second)
- **Environment separation**: Production uses minimal surface area

### Deployment Security
- **Edge deployment**: Automatic DDoS protection via Cloudflare
- **Minimal dependencies**: Reduced attack surface
- **Environment variables**: Secure configuration management
- **No secrets**: API calls to public Leetify endpoints only

## ğŸš€ Deployment Options

### 1. Cloudflare Workers (Primary)
```bash
npm run deploy:workers
```
- **Pros**: Global edge deployment, automatic scaling, zero maintenance
- **Cons**: No AI integration, resource limits

### 2. Vercel (Alternative)
```bash
npm run deploy:vercel  
```
- **Pros**: Easy deployment, good performance
- **Cons**: Function timeouts, cold starts

### 3. Railway (Alternative)
```bash
# Configure railway.json and deploy
```
- **Pros**: Full Node.js environment, can include AI
- **Cons**: More expensive, requires management

### 4. Local MCP Server
```bash
npm run dev
```
- **Pros**: Full feature set, AI integration, no limits
- **Cons**: Requires local setup, not globally accessible

## ğŸ§ª Quality Assurance

### Test Coverage
- **Unit Tests**: ~77% coverage (handlers, services, utilities)
- **Integration Tests**: End-to-end workflow validation
- **Statistical Tests**: Property-based testing for mathematical correctness
- **Performance Tests**: Response time and memory usage benchmarks

### Validation Strategy
- **Type Safety**: Full TypeScript with strict mode
- **Input Validation**: Zod schemas for all API inputs
- **Statistical Accuracy**: Validation against known results
- **Error Handling**: Graceful degradation for all failure modes

## ğŸ“ˆ Success Metrics

### Technical Performance
- âœ… **Response Time**: <5 seconds achieved
- âœ… **Deployment**: Zero-downtime edge deployment
- âœ… **Reliability**: Automatic error recovery and fallbacks
- âœ… **Scalability**: Edge deployment handles global traffic

### User Experience
- âœ… **Accessibility**: No setup required (HTTP API)
- âœ… **Accuracy**: Research-validated statistical thresholds
- âœ… **Actionability**: Specific, statistical-backed recommendations
- âœ… **Consistency**: Same analysis engine across all deployment modes

## ğŸ› ï¸ Development Workflow

### Adding New Features
1. **Design**: Plan in TASK.md with clear acceptance criteria
2. **Implement**: Follow modular architecture patterns
3. **Test**: Unit tests + integration tests + statistical validation
4. **Deploy**: Verify local MCP â†’ deploy to production HTTP API
5. **Document**: Update README and PLANNING.md

### Code Quality Standards
- **TypeScript**: Strict mode with no implicit any
- **ESLint**: Consistent code style
- **File Limits**: Max 500 lines per file
- **Documentation**: JSDoc for all public functions
- **Testing**: >77% coverage with focus on critical paths

## ğŸ”® Future Roadmap

### Short Term
- **Enhanced Error Handling**: Better user feedback for edge cases
- **Performance Optimization**: Further statistical computation speedups
- **Additional Metrics**: Expand statistical analysis capabilities

### Long Term
- **Real-time Analysis**: Live match analysis integration
- **Team Analysis**: Multi-player coordination metrics
- **Advanced ML**: Neural network pattern recognition
- **Mobile Integration**: API client libraries and SDKs

---

This architecture provides a solid foundation for both immediate production use (HTTP API) and advanced local development (MCP + AI), with clear separation of concerns and deployment flexibility.