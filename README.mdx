

<p align="center">
  <img src="./assets/banner.png" alt="CS2 AI Coach Banner" height="48"/>
</p>

<p align="center">
  <a href="https://github.com/sord-dev/cs2-coach/actions">
    <img src="https://img.shields.io/github/actions/workflow/status/sord-dev/cs2-coach/ci.yml?branch=main" alt="Build Status"/>
  </a>
  <a href="LICENSE">
    <img src="https://img.shields.io/badge/license-MIT-blue.svg" alt="License"/>
  </a>
</p>

# CS2 AI Coach

<p align="center"><b>Statistical Analysis Engine</b></p>

<p align="center">
  âš¡ <b>Fast, privacy-first Counter-Strike 2 coaching assistant</b><br/>
  Advanced statistical analysis & <b>optional local AI</b>.<br/>
  Deploy as an MCP server or HTTP API in minutes.
</p>

[//]: # "Demo section (add a GIF or screenshot here for visual context)"


<details>
<summary><b>âœ¨ What can it do?</b></summary>

- **Personalized coaching advice** with research-validated stats
- **Flow state & tilt detection** for peak performance
- **Actionable practice routines** and improvement tracking
- **Deploy anywhere**: Cloudflare, local, or integrate with Claude Desktop

</details>


---

## ðŸš€ Quick Start

- **Try the HTTP API:** [API Docs & Tutorial](docs/http-api-docs.md)
- **Run Locally:** [Setup & Architecture](docs/architecture.md)

## ðŸ“š Documentation

- [Analysis Methodology](docs/analysis-methadology.md)
- [HTTP API Reference](docs/http-api-docs.md)
- [MCP API Reference](docs/mcp-api-docs.md)
- [System Architecture](docs/architecture.md)

---


## ðŸ¤– Enable Local AI (Ollama)


> **Optional:** For AI-powered commentary and deeper insights, you can run a local Ollama model.  
> **Statistical analysis works out of the box without AI!**


1. **Download & Install Ollama**  
  [![Ollama Logo](https://ollama.ai/public/ollama-logo.svg)](https://ollama.ai/download) [Download Ollama](https://ollama.ai/download)  
  Follow the instructions for your OS (Windows, Mac, Linux).

2. **Start Ollama**
  ```bash
  ollama serve
  ```

3. **Create the CS2 Coach Model**
  ```bash
  ollama create cs2-coach -f ./modelfiles/cs2-coach-enhanced.modelfile
  ```

4. **Configure your `.env`**
  ```env
  DISABLE_AI=false
  OLLAMA_BASE_URL=http://localhost:11434
  OLLAMA_MODEL=cs2-coach
  ```



<details>
<summary><b>ðŸ’¡ Need help?</b></summary>

See [Architecture & Setup](docs/architecture.md) for troubleshooting and advanced configuration.

</details>

---


---

## ðŸ§ª Testing & Development

- **Run all tests:** `npm test` (see [architecture.md](docs/architecture.md) for more)
- **Lint/typecheck:** `npm run lint` / `npm run typecheck`
- **Start dev server:** `npm run dev`


---

## ðŸ“„ License

MIT License â€“ see `LICENSE` file for details.


## ðŸ™‹ Support

For troubleshooting, health checks, and advanced usage, see the [docs/](docs/) directory or [open an issue](https://github.com/sord-dev/cs2-coach/issues) if needed.

## ðŸ”— Related Links

- [MCP Protocol Specification](https://modelcontextprotocol.io/specification/2025-06-18)
- [Ollama Documentation](https://github.com/ollama/ollama)
- [Leetify API Documentation](https://api-public-docs.cs-prod.leetify.com/)
- [TypeScript SDK for MCP](https://github.com/modelcontextprotocol/typescript-sdk)